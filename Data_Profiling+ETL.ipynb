{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.types import FloatType, IntegerType, DateType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, isnan, when, count, col, coalesce, lit, avg, mean, concat, concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /usr/share/java/mariadb-java-client-2.5.3.jar pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /Users/majo/Documents/david/mariadb-java-client-2.5.3.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/tefy/opt/miniconda3/envs/modelos_esta/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/11/16 00:36:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "21/11/16 00:36:33 WARN DependencyUtils: Local jar /Users/majo/Documents/david/mariadb-java-client-2.5.3.jar does not exist, skipping.\n",
      "21/11/16 00:36:34 INFO SparkContext: Running Spark version 3.2.0\n",
      "21/11/16 00:36:34 INFO ResourceUtils: ==============================================================\n",
      "21/11/16 00:36:34 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "21/11/16 00:36:34 INFO ResourceUtils: ==============================================================\n",
      "21/11/16 00:36:34 INFO SparkContext: Submitted application: pyspark-shell\n",
      "21/11/16 00:36:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "21/11/16 00:36:34 INFO ResourceProfile: Limiting resource is cpu\n",
      "21/11/16 00:36:34 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "21/11/16 00:36:34 INFO SecurityManager: Changing view acls to: tefy\n",
      "21/11/16 00:36:34 INFO SecurityManager: Changing modify acls to: tefy\n",
      "21/11/16 00:36:34 INFO SecurityManager: Changing view acls groups to: \n",
      "21/11/16 00:36:34 INFO SecurityManager: Changing modify acls groups to: \n",
      "21/11/16 00:36:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tefy); groups with view permissions: Set(); users  with modify permissions: Set(tefy); groups with modify permissions: Set()\n",
      "21/11/16 00:36:34 INFO Utils: Successfully started service 'sparkDriver' on port 53818.\n",
      "21/11/16 00:36:34 INFO SparkEnv: Registering MapOutputTracker\n",
      "21/11/16 00:36:34 INFO SparkEnv: Registering BlockManagerMaster\n",
      "21/11/16 00:36:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "21/11/16 00:36:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "21/11/16 00:36:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "21/11/16 00:36:34 INFO DiskBlockManager: Created local directory at /private/var/folders/fv/hrld5h514x3f_54zf8266ddc0000gn/T/blockmgr-8c74fce8-00bc-46d6-bdae-f1867a985aad\n",
      "21/11/16 00:36:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "21/11/16 00:36:34 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "21/11/16 00:36:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "21/11/16 00:36:35 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.11:4040\n",
      "21/11/16 00:36:35 ERROR SparkContext: Failed to add file:/Users/majo/Documents/david/mariadb-java-client-2.5.3.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /Users/majo/Documents/david/mariadb-java-client-2.5.3.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:1935)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:1990)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12(SparkContext.scala:503)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12$adapted(SparkContext.scala:503)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:503)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:832)\n",
      "21/11/16 00:36:35 INFO Executor: Starting executor ID driver on host 192.168.1.11\n",
      "21/11/16 00:36:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53820.\n",
      "21/11/16 00:36:35 INFO NettyBlockTransferService: Server created on 192.168.1.11:53820\n",
      "21/11/16 00:36:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "21/11/16 00:36:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.11, 53820, None)\n",
      "21/11/16 00:36:35 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.11:53820 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.1.11, 53820, None)\n",
      "21/11/16 00:36:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.11, 53820, None)\n",
      "21/11/16 00:36:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.11, 53820, None)\n"
     ]
    }
   ],
   "source": [
    "spark_context = SparkContext()\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"/Users/majo/Desktop/Maestria_MIAD/Semestre_1/Modelado_de_Datos_y_ETL/Semana_2/Tarea_Data_Profiling/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfilamiento y Transformacion de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aeropuertos\n",
    " Realizaremos un análisis exploratorio del conjunto de datos del archivo vuelos y obtendremos algunas observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = spark.read.load(\"aeropuertos.csv\", format = \"csv\", sep = \",\", inferSchema = \"true\", header = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(_c0,IntegerType,true),StructField(sigla,StringType,true),StructField(iata,StringType,true),StructField(nombre,StringType,true),StructField(municipio,StringType,true),StructField(departamento,StringType,true),StructField(categoria,StringType,true),StructField(latitud,DoubleType,true),StructField(longitud,DoubleType,true),StructField(propietario,StringType,true),StructField(explotador,StringType,true),StructField(longitud_pista,DoubleType,true),StructField(ancho_pista,DoubleType,true),StructField(pbmo,StringType,true),StructField(elevacion,DoubleType,true),StructField(resolucion,StringType,true),StructField(fecha_construccion,StringType,true),StructField(fecha_vigencia,StringType,true),StructField(clase,StringType,true),StructField(tipo,StringType,true),StructField(numero_vuelos_origen,StringType,true),StructField(gcd_departamento,IntegerType,true),StructField(gcd_municipio,IntegerType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(aeropuertos.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de las variables del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- sigla: string (nullable = true)\n",
      " |-- iata: string (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- departamento: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- latitud: double (nullable = true)\n",
      " |-- longitud: double (nullable = true)\n",
      " |-- propietario: string (nullable = true)\n",
      " |-- explotador: string (nullable = true)\n",
      " |-- longitud_pista: double (nullable = true)\n",
      " |-- ancho_pista: double (nullable = true)\n",
      " |-- pbmo: string (nullable = true)\n",
      " |-- elevacion: double (nullable = true)\n",
      " |-- resolucion: string (nullable = true)\n",
      " |-- fecha_construccion: string (nullable = true)\n",
      " |-- fecha_vigencia: string (nullable = true)\n",
      " |-- clase: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- numero_vuelos_origen: string (nullable = true)\n",
      " |-- gcd_departamento: integer (nullable = true)\n",
      " |-- gcd_municipio: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forma de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number: 292 , columns_number: 23\n"
     ]
    }
   ],
   "source": [
    "print(f'row_number: {aeropuertos.count()} ,', f'columns_number: {len(aeropuertos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de datos\n",
    "\n",
    "De acuerdo al modelo, se seleccionara las variables o columnas a tener en cuenta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"modelo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.selectExpr('sigla','fecha_construccion as idFechaConstruccion',\n",
    "                                  'nombre as nombreAeropuerto', 'categoria','tipo', 'departamento','municipio',\n",
    "                                  'latitud','longitud','propietario','longitud_pista as longitudPista',\n",
    "                                  'ancho_pista as anchoPista', 'pbmo','elevacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar datos fechas\n",
    "Las fechas de construcción no pueden ser mayores a 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.where((aeropuertos['idFechaConstruccion']<'2014-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number: 242 , columns_number: 14\n"
     ]
    }
   ],
   "source": [
    "print(f'row_number: {aeropuertos.count()} ,', f'columns_number: {len(aeropuertos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "|sigla|idFechaConstruccion|nombreAeropuerto|categoria|tipo|departamento|municipio|latitud|longitud|propietario|longitudPista|anchoPista|pbmo|elevacion|\n",
      "+-----+-------------------+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "|    0|                  0|               0|        0|   0|           0|        0|      0|       0|          3|            0|         0|  54|        0|\n",
      "+-----+-------------------+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.select([count(when(isnan(c), c)).alias(c) for c in aeropuertos.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuertos.where(col(\"idFechaConstruccion\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast Column Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sigla: string (nullable = true)\n",
      " |-- idFechaConstruccion: string (nullable = true)\n",
      " |-- nombreAeropuerto: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- departamento: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: double (nullable = true)\n",
      " |-- longitud: double (nullable = true)\n",
      " |-- propietario: string (nullable = true)\n",
      " |-- longitudPista: double (nullable = true)\n",
      " |-- anchoPista: double (nullable = true)\n",
      " |-- pbmo: string (nullable = true)\n",
      " |-- elevacion: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.withColumn(\"idFechaConstruccion\",aeropuertos.idFechaConstruccion.cast(DateType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"nombreAeropuerto\",aeropuertos.nombreAeropuerto.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"categoria\",aeropuertos.categoria.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"tipo\",aeropuertos.tipo.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"departamento\",aeropuertos.departamento.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"municipio\",aeropuertos.municipio.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"latitud\",aeropuertos.latitud.cast(FloatType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"longitud\",aeropuertos.longitud.cast(FloatType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"propietario\",aeropuertos.propietario.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"longitudPista\",aeropuertos.longitudPista.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"anchoPista\",aeropuertos.anchoPista.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"pbmo\",aeropuertos.pbmo.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"elevacion\",aeropuertos.elevacion.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sigla: string (nullable = true)\n",
      " |-- idFechaConstruccion: date (nullable = true)\n",
      " |-- nombreAeropuerto: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- departamento: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: float (nullable = true)\n",
      " |-- longitud: float (nullable = true)\n",
      " |-- propietario: string (nullable = true)\n",
      " |-- longitudPista: integer (nullable = true)\n",
      " |-- anchoPista: integer (nullable = true)\n",
      " |-- pbmo: integer (nullable = true)\n",
      " |-- elevacion: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación Tabla Registro Aeropuertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción key Fecha-Aeropuertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuerto2 = aeropuertos.alias('aeropuerto2')\n",
    "\n",
    "aeropuertos = aeropuertos.select(year('idFechaConstruccion').alias('ano'),\n",
    "                           month('idFechaConstruccion').alias('mes'),'sigla','nombreAeropuerto','categoria','tipo','departamento','municipio','latitud','longitud',\n",
    " 'propietario','longitudPista','anchoPista','pbmo','elevacion')\n",
    "\n",
    "aeropuertos = aeropuertos.withColumn(\"ano\",aeropuertos.ano.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"mes\",aeropuertos.mes.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.fillna({\"ano\": 2017, \"mes\": 7})                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación entre el año y mes para formar llave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.select(concat_ws('-', aeropuertos.ano, aeropuertos.mes)\n",
    "                                         .alias(\"idFechaConstruccion\"),'sigla','nombreAeropuerto','categoria','tipo','departamento','municipio','latitud','longitud',\n",
    " 'propietario','longitudPista','anchoPista','pbmo','elevacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuertos = aeropuertos[['sigla','idFechaConstruccion','nombreAeropuerto','categoria','tipo','departamento','municipio','latitud','longitud',\n",
    " #'propietario','longitudPista','anchoPista','pbmo','elevacion']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificación \n",
    "* Limpieza de valores null- idFechaConstruccion\n",
    "* Tipo de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idFechaConstruccion: string (nullable = false)\n",
      " |-- sigla: string (nullable = true)\n",
      " |-- nombreAeropuerto: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- departamento: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: float (nullable = true)\n",
      " |-- longitud: float (nullable = true)\n",
      " |-- propietario: string (nullable = true)\n",
      " |-- longitudPista: integer (nullable = true)\n",
      " |-- anchoPista: integer (nullable = true)\n",
      " |-- pbmo: integer (nullable = true)\n",
      " |-- elevacion: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aeropuertos.filter(aeropuertos.idFechaConstruccion.isNull()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aeropuertos.filter(aeropuertos.elevacion.isNull()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplazo Valores Nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### * idFechaVigencia\n",
    "\n",
    "cabe resaltar que de un total **242** valores de esta columna mas del **78,5%** de los valores son nulos. Por esta razón se decir eliminar esta variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.fillna({\"pbmo\": 2000})\n",
    "aeropuertos = aeropuertos.na.replace({'nan': 'AEROCIVIL'}, 'propietario')\n",
    "#aeropuertos.groupBy('pbmo').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "|idFechaConstruccion|sigla|nombreAeropuerto|categoria|tipo|departamento|municipio|latitud|longitud|propietario|longitudPista|anchoPista|pbmo|elevacion|\n",
      "+-------------------+-----+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "|                  0|    0|               0|        0|   0|           0|        0|      0|       0|          0|            0|         0|   0|        0|\n",
      "+-------------------+-----+----------------+---------+----+------------+---------+-------+--------+-----------+-------------+----------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.select([count(when(isnan(c), c)).alias(c) for c in aeropuertos.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuertos = aeropuertos[''].dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number: 242 , columns_number: 14\n"
     ]
    }
   ],
   "source": [
    "print(f'row_number: {aeropuertos.count()} ,', f'columns_number: {len(aeropuertos.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.dropDuplicates(['sigla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|sigla|count|\n",
      "+-----+-----+\n",
      "|  9MN|    1|\n",
      "|  9CL|    1|\n",
      "|  7HC|    1|\n",
      "|  9AB|    1|\n",
      "|  9CG|    1|\n",
      "|  OTU|    1|\n",
      "|  9LS|    1|\n",
      "|  NVA|    1|\n",
      "|  7GI|    1|\n",
      "|  7HM|    1|\n",
      "|  RVE|    1|\n",
      "|  9BB|    1|\n",
      "|  9MP|    1|\n",
      "|  9BI|    1|\n",
      "|  9CD|    1|\n",
      "|  BEC|    1|\n",
      "|  ACD|    1|\n",
      "|  YPP|    1|\n",
      "|  PUU|    1|\n",
      "|  9LR|    1|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.groupBy('sigla').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number: 212 , columns_number: 14\n"
     ]
    }
   ],
   "source": [
    "print(f'row_number: {aeropuertos.count()} ,', f'columns_number: {len(aeropuertos.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 00:37:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "aeropuertos.toPandas().to_csv('RegistroAeropuerto.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuertos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos[\"idFechaConstruccion\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "aeropuertos['ano'] = pd.DatetimeIndex(aeropuertos['idFechaConstruccion']).year\n",
    "aeropuertos['mes'] = pd.DatetimeIndex(aeropuertos['idFechaConstruccion']).month\n",
    "aeropuertos['ano'] = aeropuertos['ano'].fillna(method=\"backfill\")\n",
    "aeropuertos['mes'] = aeropuertos['mes'].fillna(method=\"backfill\")\n",
    "aeropuertos[\"idFechaConstruccion\"] = aeropuertos[\"idFechaConstruccion\"].fillna(method=\"backfill\")\n",
    "aeropuertos['ano'] = aeropuertos['ano'].astype(int)\n",
    "aeropuertos['mes'] = aeropuertos['mes'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos['ano'] = aeropuertos['ano'].astype(str)\n",
    "aeropuertos['mes'] = aeropuertos['mes'].astype(str)\n",
    "aeropuertos[\"idFechaConstruccion\"] = aeropuertos[['ano','mes']].apply('-'.join, axis=1)\n",
    "aeropuertos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.drop(['ano','mes'], axis=1)\n",
    "aeropuertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos=spark.createDataFrame(aeropuertos) \n",
    "aeropuertos.printSchema()\n",
    "#aeropuertos.to_csv('registroaeropuerto.csv',sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos = aeropuertos.withColumn(\"idFechaConstruccion\",aeropuertos.idFechaConstruccion.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"nombreAeropuerto\",aeropuertos.nombreAeropuerto.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"categoria\",aeropuertos.categoria.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"tipo\",aeropuertos.tipo.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"departamento\",aeropuertos.departamento.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"municipio\",aeropuertos.municipio.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"latitud\",aeropuertos.latitud.cast(FloatType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"longitud\",aeropuertos.longitud.cast(FloatType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"propietario\",aeropuertos.propietario.cast(StringType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"longitudPista\",aeropuertos.longitudPista.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"anchoPista\",aeropuertos.anchoPista.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"pbmo\",aeropuertos.pbmo.cast(IntegerType()))\n",
    "aeropuertos = aeropuertos.withColumn(\"elevacion\",aeropuertos.elevacion.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aeropuertos['idFecha']= aeropuertos.index\n",
    "#aeropuertos = aeropuertos[['sigla', 'idFecha','idFechaConstruccion', 'nombreAeropuerto', 'categoria', 'tipo',\n",
    "       #'departamento', 'municipio', 'latitud', 'longitud', 'propietario',\n",
    "       #'longitudPista', 'anchoPista', 'pbmo', 'elevacion']]\n",
    "#aeropuertos['idFechaConstruccion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(aeropuertos, data, on='idFechaConstruccion')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos = spark.read.load(\"vuelos.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vuelos.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de datos\n",
    "\n",
    "De acuerdo al modelo, se seleccionara las variables o columnas a tener en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos = vuelos.selectExpr('ano', 'mes','origen','destino', \n",
    "                         'tipo_equipo as tipoEquipo','tipo_vuelo as tipoVuelo',\n",
    "                         'trafico as tipoTrafico','empresa','vuelos as numeroVuelos',\n",
    "                          'sillas as numeroSillas', 'carga_ofrecida as cargaOfrecida', \n",
    "                           'pasajeros as numeroPasajeros','carga_bordo as cargaAbordo'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forma de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'row_number: {vuelos.count()} ,', f'columns_number: {len(vuelos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.select([count(when(isnan(c), c)).alias(c) for c in vuelos.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast Column Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos = vuelos.withColumn(\"numeroVuelos\",vuelos[\"numeroVuelos\"].cast(IntegerType()))\n",
    "vuelos = vuelos.withColumn(\"numeroSillas\",vuelos[\"numeroSillas\"].cast(IntegerType()))\n",
    "vuelos = vuelos.withColumn(\"numeroPasajeros\",vuelos[\"numeroPasajeros\"].cast(IntegerType()))\n",
    "vuelos = vuelos.withColumn(\"cargaOfrecida\",vuelos[\"cargaOfrecida\"].cast(IntegerType()))\n",
    "vuelos = vuelos.withColumn(\"cargaAbordo\",vuelos[\"cargaAbordo\"].cast(IntegerType()))\n",
    "vuelos = vuelos.withColumn(\"tipoTrafico\",vuelos[\"tipoTrafico\"].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_vuelos = vuelos.agg({'numeroVuelos': 'avg'})\n",
    "promedio_vuelos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.groupBy('tipoTrafico').count().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_vuelos = vuelos.agg({'numeroVuelos': 'avg'})\n",
    "vuelos = vuelos.fillna({'numeroVuelos': promedio_vuelos.first()[0]})\n",
    "\n",
    "promedio_sillas = vuelos.agg({'numeroSillas': 'avg'})\n",
    "vuelos = vuelos.fillna({'numeroSillas': promedio_sillas.first()[0]})\n",
    "\n",
    "#sillas_por_avion = vuelos[[\"numeroSillas\",\"tipoEquipo\"]]\n",
    "#promedio_sillas = sillas_por_avion.groupby(\"tipoEquipo\").mean()\n",
    "#vuelos = vuelos.fillna({'numeroSillas': promedio_sillas.first()[0]})\n",
    "\n",
    "promedio_pasajeros = vuelos.agg({'numeroPasajeros': 'avg'})\n",
    "vuelos = vuelos.fillna({'numeroPasajeros': promedio_pasajeros.first()[0]})\n",
    "\n",
    "vuelos = vuelos.na.replace({'nan': 'N'}, 'tipoTrafico')\n",
    "\n",
    "vuelos.groupBy('tipoTrafico').count().orderBy('count', ascending = False).show()\n",
    "vuelos[['tipoEquipo', 'numeroSillas', 'numeroPasajeros', 'numeroVuelos', 'tipoVuelo']].show()\n",
    "\n",
    "vuelos.groupBy('tipoEquipo').count().orderBy('count', ascending=False).show()\n",
    "\n",
    "vuelos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos.select([count(when(isnan(c), c)).alias(c) for c in vuelos.columns]).show()\n",
    "vuelos.where(col(\"trafico\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos = vuelos.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'row_number: {vuelos.count()} ,', f'columns_number: {len(vuelos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion Tablas Modelo Multidimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trayecto Vuelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ruta = vuelos[['origen', 'destino']]\n",
    "Ruta = Ruta.select(concat(Ruta.origen, Ruta.destino).alias(\"idRuta\"),\"origen\", \"destino\")\n",
    "Ruta = Ruta.dropDuplicates()\n",
    "Ruta.show(truncate = False)\n",
    "#Ruta.toPandas().to_csv('TrayectoVuelo.csv', sep=',', index=False)\n",
    "#Ruta.write.option('encoding', 'UTF-8').csv(\"trayecto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ruta.toPandas().to_csv('TrayectoVuelo.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "import pandas as pd\n",
    "# explicit function\n",
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1, df2: df1.union(df2.select(df1.columns)), dfs)\n",
    "  \n",
    "\n",
    "Fecha1 = vuelos[['ano', 'mes']]\n",
    "#Fecha1 = Fecha1.withColumn(\"dia\", lit(\"01\"))\n",
    "\n",
    "Fecha2 = aeropuertos[['idFechaConstruccion']]\n",
    "Fecha2 = aeropuertos.select(year('idFechaConstruccion').alias('ano'),\n",
    "                           month('idFechaConstruccion').alias('mes')\n",
    "                           #dayofmonth('idFechaConstruccion').alias('dia')\n",
    "                           )\n",
    "\n",
    "Fecha = unionAll([Fecha1, Fecha2])\n",
    "Fecha = Fecha.select(concat_ws('-',Fecha.ano, Fecha.mes)\n",
    "                                         .alias(\"idFecha\"), 'ano','mes')\n",
    "\n",
    "Fecha.show(truncate = False)\n",
    "Fecha= Fecha.toPandas()\n",
    "\n",
    "Fecha['ano'] = Fecha['ano'].fillna(method=\"backfill\")\n",
    "Fecha['mes'] = Fecha['mes'].fillna(method=\"backfill\")\n",
    "Fecha['ano'] = Fecha['ano'].astype(int)\n",
    "Fecha['mes'] = Fecha['mes'].astype(int)\n",
    "Fecha['idFecha'] = Fecha['idFecha'].astype(str)\n",
    "\n",
    "Fecha.to_csv('fecha.csv',sep=';', index=False)\n",
    "#Fecha.write.option('encoding', 'UTF-8').csv(\"fecha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fecha['idFecha'] = Fecha['idFecha'].astype(str)\n",
    "#fechas_unicas = Fecha['idFecha'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame(fechas_unicas, columns = ['keyFecha'])\n",
    "#data['idFecha']= data.index\n",
    "#data.set_index('idFecha')\n",
    "#data= data[['idFecha', 'keyFecha']]\n",
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fecha.columns=['keyFecha','ano','mes']\n",
    "#Fecha['idFecha']= Fecha.index\n",
    "#Fecha = Fecha[['idFecha','keyFecha','ano','mes']]\n",
    "#Fecha['keyFecha'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fecha_final=pd.merge(Fecha, data, on='keyFecha')\n",
    "#Fecha_final= Fecha_final.drop(['idFecha_x'], axis=1)\n",
    "#Fecha_final=Fecha_final[['idFecha_y','keyFecha','ano','mes']]\n",
    "#Fecha_final.columns = ['idFecha','keyFecha','ano','mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fecha_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'row_number: {Fecha.count()} ,', f'columns_number: {len(Fecha.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'row_number: {Fecha1.count()} ,', f'columns_number: {len(Fecha1.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'row_number: {Fecha2.count()} ,', f'columns_number: {len(Fecha2.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro Vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_vuelos = vuelos[['ano', 'mes', 'origen', 'destino',\"tipoEquipo\",\"tipoVuelo\",\"tipoTrafico\",\"empresa\" ,'numeroVuelos', 'numeroPasajeros', 'numeroSillas', 'cargaOfrecida', 'cargaAbordo',]]\n",
    "#registro_vuelos = registro_vuelos.withColumn(\"dia\")\n",
    "registro_vuelos = registro_vuelos.select(concat_ws('-', registro_vuelos.ano, registro_vuelos.mes)\n",
    "                                         .alias(\"idFecha\"),concat(registro_vuelos.origen, registro_vuelos.destino)\n",
    "                                         .alias(\"idRuta\"), \"tipoEquipo\",\"tipoVuelo\",\"tipoTrafico\",\"empresa\",'numeroVuelos', 'numeroPasajeros', 'numeroSillas', 'cargaOfrecida', 'cargaAbordo')\n",
    "registro_vuelos = registro_vuelos.dropDuplicates()\n",
    "registro_vuelos.show(truncate = False)\n",
    "#registro_vuelos.write.option('encoding', 'UTF-8').csv(\"registroVuelos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_vuelos.toPandas().to_csv('RegistroVuelos.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registro_vuelos.columns = ['keyFecha','idRuta','numeroVuelos','numeroPasajeros','numeroSillas','cargaOfrecida','cargaAbordo']\n",
    "#registro_vuelos['idFecha']= registro_vuelos.index\n",
    "#registro_vuelos = registro_vuelos[['idFecha','keyFecha','idRuta','numeroVuelos','numeroPasajeros','numeroSillas','cargaOfrecida','cargaAbordo']]\n",
    "#registro_vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registro_vuelos= pd.merge(registro_vuelos, data, on='keyFecha')\n",
    "#registro_vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registro_vuelos = registro_vuelos.drop(['idFecha_y','idFecha_x'], axis=1)\n",
    "#registro_vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registro_vuelos=registro_vuelos[['idFecha','keyFecha','idRuta','numeroVuelos','numeroPasajeros','numeroSillas','cargaOfrecida','cargaAbordo']]\n",
    "#registro_vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registro_vuelos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
